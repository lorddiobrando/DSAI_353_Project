{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\nimport urllib.request\nimport zipfile\nimport os\nimport re\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:14:21.973750Z","iopub.execute_input":"2025-05-10T21:14:21.974003Z","iopub.status.idle":"2025-05-10T21:14:32.349528Z","shell.execute_reply.started":"2025-05-10T21:14:21.973981Z","shell.execute_reply":"2025-05-10T21:14:32.348950Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:14:32.350753Z","iopub.execute_input":"2025-05-10T21:14:32.351202Z","iopub.status.idle":"2025-05-10T21:14:32.446684Z","shell.execute_reply.started":"2025-05-10T21:14:32.351183Z","shell.execute_reply":"2025-05-10T21:14:32.446080Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset = load_dataset(\"imdb\")\ntrain_data = dataset[\"train\"]\ntest_data = dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:14:32.447559Z","iopub.execute_input":"2025-05-10T21:14:32.447853Z","iopub.status.idle":"2025-05-10T21:14:39.602927Z","shell.execute_reply.started":"2025-05-10T21:14:32.447826Z","shell.execute_reply":"2025-05-10T21:14:39.602360Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecebcac3eb9e42909d52482e63e54240"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ec2c66371cb4d41a95778bbbed82124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b79cf3d50c643c88a75aaac73a6fe0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a04603f9e14cddb734d92cf3a3d0c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ea919610b14cdaad6a00733e685d86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a95a0422e6cc4dbeb3e45b53792e34af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bca80816723438eb69819c13c7fe38a"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def simple_tokenizer(text):\n    return re.findall(r\"\\b\\w+\\b\", text.lower())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:14:39.604433Z","iopub.execute_input":"2025-05-10T21:14:39.604972Z","iopub.status.idle":"2025-05-10T21:14:39.607954Z","shell.execute_reply.started":"2025-05-10T21:14:39.604953Z","shell.execute_reply":"2025-05-10T21:14:39.607431Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def encode(text, vocab, max_len=500):\n    tokens = simple_tokenizer(text)\n    ids = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens[:max_len]]\n    if len(ids) < max_len:\n        ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))\n    return ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:14:39.608753Z","iopub.execute_input":"2025-05-10T21:14:39.608984Z","iopub.status.idle":"2025-05-10T21:14:39.630562Z","shell.execute_reply.started":"2025-05-10T21:14:39.608956Z","shell.execute_reply":"2025-05-10T21:14:39.630009Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def load_glove_embeddings(glove_file_path, vocab, embedding_dim=300):\n    embeddings_index = {}\n    with open(glove_file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            values = line.strip().split()\n            word = values[0]\n            vector = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = vector\n    embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocab), embedding_dim)).astype(np.float32)\n    for word, idx in vocab.items():\n        if word in embeddings_index:\n            embedding_matrix[idx] = embeddings_index[word]\n    return torch.tensor(embedding_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:14:39.631279Z","iopub.execute_input":"2025-05-10T21:14:39.631535Z","iopub.status.idle":"2025-05-10T21:14:39.652454Z","shell.execute_reply.started":"2025-05-10T21:14:39.631516Z","shell.execute_reply":"2025-05-10T21:14:39.651748Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"glove_path = \"glove.6B.300d.txt\"\nif not os.path.exists(glove_path):\n    urllib.request.urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", \"glove.6B.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:14:39.653238Z","iopub.execute_input":"2025-05-10T21:14:39.653944Z","iopub.status.idle":"2025-05-10T21:17:19.453689Z","shell.execute_reply.started":"2025-05-10T21:14:39.653920Z","shell.execute_reply":"2025-05-10T21:17:19.453017Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"with zipfile.ZipFile(\"/kaggle/working/glove.6B.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\".\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:19.456088Z","iopub.execute_input":"2025-05-10T21:17:19.456289Z","iopub.status.idle":"2025-05-10T21:17:33.364580Z","shell.execute_reply.started":"2025-05-10T21:17:19.456269Z","shell.execute_reply":"2025-05-10T21:17:33.364011Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def evaluate(model, loader):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x).squeeze()\n            preds = (outputs > 0.5).int()\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    return acc, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:33.365269Z","iopub.execute_input":"2025-05-10T21:17:33.365473Z","iopub.status.idle":"2025-05-10T21:17:33.370446Z","shell.execute_reply.started":"2025-05-10T21:17:33.365458Z","shell.execute_reply":"2025-05-10T21:17:33.369691Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class IMDBDataset(Dataset):\n    def __init__(self, split, vocab):\n        self.texts = split[\"text\"]\n        self.labels = split[\"label\"]\n        self.vocab = vocab\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        x = encode(self.texts[idx], self.vocab)\n        y = self.labels[idx]\n        return torch.tensor(x), torch.tensor(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:33.371241Z","iopub.execute_input":"2025-05-10T21:17:33.371505Z","iopub.status.idle":"2025-05-10T21:17:33.388471Z","shell.execute_reply.started":"2025-05-10T21:17:33.371490Z","shell.execute_reply":"2025-05-10T21:17:33.387962Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class Chomp1d(nn.Module):\n    def __init__(self, chomp_size):\n        super().__init__()\n        self.chomp_size = chomp_size\n\n    def forward(self, x):\n        return x[:, :, :-self.chomp_size]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:33.389085Z","iopub.execute_input":"2025-05-10T21:17:33.389743Z","iopub.status.idle":"2025-05-10T21:17:33.406949Z","shell.execute_reply.started":"2025-05-10T21:17:33.389722Z","shell.execute_reply":"2025-05-10T21:17:33.406371Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class TemporalBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dilation, padding, dropout=0.2):\n        super().__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n                               padding=padding, dilation=dilation)\n        self.chomp1 = Chomp1d(padding)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.relu1 = nn.ReLU()\n        self.dropout1 = nn.Dropout(dropout)\n\n        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n                               padding=padding, dilation=dilation)\n        self.chomp2 = Chomp1d(padding)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n        self.relu2 = nn.ReLU()\n        self.dropout2 = nn.Dropout(dropout)\n\n        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.chomp1(out)\n        out = self.bn1(out)\n        out = self.relu1(out)\n        out = self.dropout1(out)\n\n        out = self.conv2(out)\n        out = self.chomp2(out)\n        out = self.bn2(out)\n        out = self.relu2(out)\n        out = self.dropout2(out)\n\n        res = x if self.downsample is None else self.downsample(x)\n        return self.relu(out + res)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:33.407791Z","iopub.execute_input":"2025-05-10T21:17:33.408425Z","iopub.status.idle":"2025-05-10T21:17:33.428048Z","shell.execute_reply.started":"2025-05-10T21:17:33.408402Z","shell.execute_reply":"2025-05-10T21:17:33.427394Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class TCN(nn.Module):\n    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n        super().__init__()\n        layers = []\n        for i in range(len(num_channels)):\n            dilation = 2 ** i\n            in_channels = num_inputs if i == 0 else num_channels[i - 1]\n            out_channels = num_channels[i]\n            layers += [TemporalBlock(in_channels, out_channels, kernel_size, dilation,\n                                     padding=(kernel_size - 1) * dilation, dropout=dropout)]\n        self.network = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.network(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:33.428718Z","iopub.execute_input":"2025-05-10T21:17:33.428973Z","iopub.status.idle":"2025-05-10T21:17:33.451206Z","shell.execute_reply.started":"2025-05-10T21:17:33.428956Z","shell.execute_reply":"2025-05-10T21:17:33.450706Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class SentimentModel(nn.Module):\n    def __init__(self, embedding_matrix, hidden_channels=[128, 128]):\n        super().__init__()\n        vocab_size, embedding_dim = embedding_matrix.shape\n        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n        self.conv1 = nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n        self.relu1 = nn.ReLU()\n        self.pool = nn.MaxPool1d(2)\n        self.batch_norm = nn.BatchNorm1d(128)\n\n        self.tcn = TCN(128, hidden_channels)\n        self.layer_norm = nn.LayerNorm(hidden_channels[-1])\n        self.global_pool = nn.AdaptiveMaxPool1d(1)\n\n        self.fc = nn.Linear(hidden_channels[-1], 1)\n\n    def forward(self, x):\n        x = self.embedding(x).permute(0, 2, 1)      # (B, C, T)\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.pool(x)\n        x = self.batch_norm(x)\n        x = self.tcn(x)\n        x = self.global_pool(x).squeeze(-1)\n        x = self.layer_norm(x)\n        return torch.sigmoid(self.fc(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:33.451858Z","iopub.execute_input":"2025-05-10T21:17:33.452104Z","iopub.status.idle":"2025-05-10T21:17:33.468830Z","shell.execute_reply.started":"2025-05-10T21:17:33.452080Z","shell.execute_reply":"2025-05-10T21:17:33.468348Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from collections import Counter\ncounter = Counter()\n\nfor example in train_data:\n    counter.update(simple_tokenizer(example[\"text\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:33.469478Z","iopub.execute_input":"2025-05-10T21:17:33.470123Z","iopub.status.idle":"2025-05-10T21:17:36.726173Z","shell.execute_reply.started":"2025-05-10T21:17:33.470106Z","shell.execute_reply":"2025-05-10T21:17:36.725371Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\nfor word, freq in counter.items():\n    if freq >= 5:\n        vocab[word] = len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:36.726897Z","iopub.execute_input":"2025-05-10T21:17:36.727124Z","iopub.status.idle":"2025-05-10T21:17:36.750405Z","shell.execute_reply.started":"2025-05-10T21:17:36.727108Z","shell.execute_reply":"2025-05-10T21:17:36.749553Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_dataset = IMDBDataset(train_data, vocab)\ntest_dataset = IMDBDataset(test_data, vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:36.751212Z","iopub.execute_input":"2025-05-10T21:17:36.751475Z","iopub.status.idle":"2025-05-10T21:17:38.749808Z","shell.execute_reply.started":"2025-05-10T21:17:36.751454Z","shell.execute_reply":"2025-05-10T21:17:38.748306Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:38.753292Z","iopub.execute_input":"2025-05-10T21:17:38.753617Z","iopub.status.idle":"2025-05-10T21:17:39.773804Z","shell.execute_reply.started":"2025-05-10T21:17:38.753595Z","shell.execute_reply":"2025-05-10T21:17:39.772875Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"embedding_dim = 300\nglove_path = \"glove.6B.300d.txt\"  # make sure this file is present\nembedding_matrix = load_glove_embeddings(glove_path, vocab, embedding_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:17:39.774722Z","iopub.execute_input":"2025-05-10T21:17:39.774976Z","iopub.status.idle":"2025-05-10T21:18:03.023895Z","shell.execute_reply.started":"2025-05-10T21:17:39.774955Z","shell.execute_reply":"2025-05-10T21:18:03.023053Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SentimentModel(embedding_matrix).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.BCELoss()\n\n# Training loop\nbest_f1 = 0\npatience = 2\nepochs_no_improve = 0\n\nfor epoch in range(10):\n    model.train()\n    total_loss = 0\n    for x, y in tqdm(train_loader):\n        x, y = x.to(device), y.float().to(device)\n        optimizer.zero_grad()\n        outputs = model(x).squeeze()\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    val_acc, val_f1 = evaluate(model, test_loader)\n    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Test Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n\n    if val_f1 > best_f1:\n        best_f1 = val_f1\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(\"Early stopping.\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:18:03.027163Z","iopub.execute_input":"2025-05-10T21:18:03.027400Z","iopub.status.idle":"2025-05-10T21:19:46.586155Z","shell.execute_reply.started":"2025-05-10T21:18:03.027382Z","shell.execute_reply":"2025-05-10T21:19:46.585472Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 391/391 [00:14<00:00, 26.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 144.5528, Test Acc: 0.8567, F1: 0.8676\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:12<00:00, 31.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 101.3599, Test Acc: 0.8350, F1: 0.8547\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:12<00:00, 31.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 77.2652, Test Acc: 0.8864, F1: 0.8888\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:12<00:00, 31.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 55.7087, Test Acc: 0.8774, F1: 0.8714\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 391/391 [00:12<00:00, 30.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 40.4622, Test Acc: 0.8758, F1: 0.8828\nEarly stopping.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"torch.save(model.state_dict(), \"TCN_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:19:51.901396Z","iopub.execute_input":"2025-05-10T21:19:51.902102Z","iopub.status.idle":"2025-05-10T21:19:52.021646Z","shell.execute_reply.started":"2025-05-10T21:19:51.902070Z","shell.execute_reply":"2025-05-10T21:19:52.020665Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# For later use if needed\nmodel = SentimentModel(embedding_matrix).to(device)\nmodel.load_state_dict(torch.load(\"TCN_model.pth\"))\nmodel.eval()  # Set to evaluation mode","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}