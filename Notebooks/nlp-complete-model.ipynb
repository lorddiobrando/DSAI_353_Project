{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport urllib.request\nimport zipfile\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom collections import Counter\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:23:55.041724Z","iopub.execute_input":"2025-05-10T21:23:55.042013Z","iopub.status.idle":"2025-05-10T21:24:01.938326Z","shell.execute_reply.started":"2025-05-10T21:23:55.041989Z","shell.execute_reply":"2025-05-10T21:24:01.937234Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:24:19.076618Z","iopub.execute_input":"2025-05-10T21:24:19.076931Z","iopub.status.idle":"2025-05-10T21:24:19.165572Z","shell.execute_reply.started":"2025-05-10T21:24:19.076908Z","shell.execute_reply":"2025-05-10T21:24:19.164613Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def load_glove_embeddings(glove_file_path, vocab, embedding_dim=100):\n    embeddings_index = {}\n    with open(glove_file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            values = line.strip().split()\n            word = values[0]\n            vector = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = vector\n    embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocab), embedding_dim)).astype(np.float32)\n    for word, idx in vocab.items():\n        if word in embeddings_index:\n            embedding_matrix[idx] = embeddings_index[word]\n    return torch.tensor(embedding_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:24:20.324271Z","iopub.execute_input":"2025-05-10T21:24:20.324957Z","iopub.status.idle":"2025-05-10T21:24:20.332560Z","shell.execute_reply.started":"2025-05-10T21:24:20.324925Z","shell.execute_reply":"2025-05-10T21:24:20.331620Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"glove_path = \"glove.6B.300d.txt\"\nif not os.path.exists(glove_path):\n    urllib.request.urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", \"glove.6B.zip\")\n    with zipfile.ZipFile(\"glove.6B.zip\", 'r') as zip_ref:\n        zip_ref.extractall(\".\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:24:21.971223Z","iopub.execute_input":"2025-05-10T21:24:21.971514Z","iopub.status.idle":"2025-05-10T21:27:15.951730Z","shell.execute_reply.started":"2025-05-10T21:24:21.971491Z","shell.execute_reply":"2025-05-10T21:27:15.951110Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class TemporalBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n        super().__init__()\n        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n                              padding=(kernel_size - 1) * dilation, dilation=dilation)\n        self.relu = nn.ReLU()\n        self.norm = nn.BatchNorm1d(out_channels)\n\n    def forward(self, x):\n        return self.norm(self.relu(self.conv(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:27:15.952998Z","iopub.execute_input":"2025-05-10T21:27:15.953276Z","iopub.status.idle":"2025-05-10T21:27:15.960052Z","shell.execute_reply.started":"2025-05-10T21:27:15.953247Z","shell.execute_reply":"2025-05-10T21:27:15.959166Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class TCN(nn.Module):\n    def __init__(self, in_channels, out_channels, num_levels=3):\n        super().__init__()\n        layers = []\n        for i in range(num_levels):\n            dilation = 2 ** i\n            in_ch = in_channels if i == 0 else out_channels\n            layers.append(TemporalBlock(in_ch, out_channels, kernel_size=3, dilation=dilation))\n        self.network = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.network(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:27:15.961185Z","iopub.execute_input":"2025-05-10T21:27:15.961460Z","iopub.status.idle":"2025-05-10T21:27:15.973371Z","shell.execute_reply.started":"2025-05-10T21:27:15.961432Z","shell.execute_reply":"2025-05-10T21:27:15.972730Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class SentimentModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n        super().__init__()\n        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=vocab[\"<pad>\"])\n        self.conv1 = nn.Conv1d(embedding_dim, 128, kernel_size=5)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(kernel_size=2)\n\n        self.tcn = TCN(128, 64)\n        self.ln = nn.LayerNorm(64)\n\n        self.bilstm = nn.LSTM(input_size=64, hidden_size=hidden_dim, bidirectional=True, batch_first=True)\n        self.dropout_lstm = nn.Dropout(0.3)  # Added dropout after LSTM\n        self.global_pool = nn.AdaptiveMaxPool1d(1)\n\n        self.fc1 = nn.Linear(hidden_dim * 2, 64)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(64, 1)\n        nn.init.constant_(self.fc2.bias, -1.0)  # Help escape flat start\n\n    def forward(self, x):\n        x = self.embedding(x)              # [B, L, E]\n        x = x.permute(0, 2, 1)             # [B, E, L]\n\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))  # [B, C, L//2]\n\n        x = self.tcn(x)\n        x = x.permute(0, 2, 1)             # [B, L, C]\n        x = self.ln(x)\n\n        lstm_out, _ = self.bilstm(x)       # [B, L, 2H]\n        lstm_out = self.dropout_lstm(lstm_out)  # Added dropout\n        lstm_out = lstm_out.permute(0, 2, 1)\n        pooled = self.global_pool(lstm_out).squeeze(-1)\n\n        x = self.dropout(F.relu(self.fc1(pooled)))\n        return torch.sigmoid(self.fc2(x)).squeeze()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:34.642940Z","iopub.execute_input":"2025-05-10T21:28:34.643612Z","iopub.status.idle":"2025-05-10T21:28:34.650679Z","shell.execute_reply.started":"2025-05-10T21:28:34.643589Z","shell.execute_reply":"2025-05-10T21:28:34.650056Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def basic_tokenizer(text):\n    text = text.lower()\n    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n    return text.split()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:36.745268Z","iopub.execute_input":"2025-05-10T21:28:36.745539Z","iopub.status.idle":"2025-05-10T21:28:36.749468Z","shell.execute_reply.started":"2025-05-10T21:28:36.745520Z","shell.execute_reply":"2025-05-10T21:28:36.748820Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def encode(text):\n    return torch.tensor([vocab.get(token, vocab[\"<unk>\"]) for token in basic_tokenizer(text)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:39.834986Z","iopub.execute_input":"2025-05-10T21:28:39.835254Z","iopub.status.idle":"2025-05-10T21:28:39.839266Z","shell.execute_reply.started":"2025-05-10T21:28:39.835235Z","shell.execute_reply":"2025-05-10T21:28:39.838540Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def collate_fn(batch):\n    texts = [encode(x[\"text\"]) for x in batch]\n    labels = torch.tensor([x[\"label\"] for x in batch], dtype=torch.float32)\n    padded = pad_sequence(texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n    return padded, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:40.858867Z","iopub.execute_input":"2025-05-10T21:28:40.859361Z","iopub.status.idle":"2025-05-10T21:28:40.863557Z","shell.execute_reply.started":"2025-05-10T21:28:40.859340Z","shell.execute_reply":"2025-05-10T21:28:40.862743Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate(loader):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            preds = model(X)\n            all_preds.extend((preds > 0.5).float().cpu())\n            all_labels.extend(y.cpu())\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    return acc, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:45.683236Z","iopub.execute_input":"2025-05-10T21:28:45.683744Z","iopub.status.idle":"2025-05-10T21:28:45.688777Z","shell.execute_reply.started":"2025-05-10T21:28:45.683721Z","shell.execute_reply":"2025-05-10T21:28:45.688086Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"dataset = load_dataset(\"imdb\")\ntrain_data = dataset[\"train\"]\ntest_data = dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:48.844260Z","iopub.execute_input":"2025-05-10T21:28:48.844524Z","iopub.status.idle":"2025-05-10T21:28:53.222864Z","shell.execute_reply.started":"2025-05-10T21:28:48.844505Z","shell.execute_reply":"2025-05-10T21:28:53.222309Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29dfcb6aa31b4f029a2524c48dc5797f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9ff0ec4b0944aa695f65e4269722b8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"167b20a358cc4620aaa08555affdfdf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef00ebcebd124f3594b5bb9e79de8ca1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1feb8e84f774c6e87bf2e3ae258e156"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df4ae62201c74c1c9d6a3658118fdf79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8382a2028c94471a3084d34f235ac28"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"counter = Counter()\nfor sample in train_data:\n    tokens = basic_tokenizer(sample[\"text\"])\n    counter.update(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:53.224068Z","iopub.execute_input":"2025-05-10T21:28:53.224309Z","iopub.status.idle":"2025-05-10T21:28:56.052020Z","shell.execute_reply.started":"2025-05-10T21:28:53.224292Z","shell.execute_reply":"2025-05-10T21:28:56.051452Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"vocab = {\"<pad>\": 0, \"<unk>\": 1}\nfor word, freq in counter.items():\n    if freq >= 2:\n        vocab[word] = len(vocab)\nvocab_size = len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:56.052665Z","iopub.execute_input":"2025-05-10T21:28:56.052894Z","iopub.status.idle":"2025-05-10T21:28:56.084516Z","shell.execute_reply.started":"2025-05-10T21:28:56.052861Z","shell.execute_reply":"2025-05-10T21:28:56.083875Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\ntest_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:56.085730Z","iopub.execute_input":"2025-05-10T21:28:56.085966Z","iopub.status.idle":"2025-05-10T21:28:56.095837Z","shell.execute_reply.started":"2025-05-10T21:28:56.085944Z","shell.execute_reply":"2025-05-10T21:28:56.095093Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"embedding_dim = 300\nembedding_matrix = load_glove_embeddings(glove_path, vocab, embedding_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:28:57.375182Z","iopub.execute_input":"2025-05-10T21:28:57.375461Z","iopub.status.idle":"2025-05-10T21:29:21.332998Z","shell.execute_reply.started":"2025-05-10T21:28:57.375441Z","shell.execute_reply":"2025-05-10T21:29:21.332175Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model = SentimentModel(vocab_size, embedding_dim, hidden_dim=128).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\ncriterion = nn.BCELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:29:21.334161Z","iopub.execute_input":"2025-05-10T21:29:21.334435Z","iopub.status.idle":"2025-05-10T21:29:23.835925Z","shell.execute_reply.started":"2025-05-10T21:29:21.334416Z","shell.execute_reply":"2025-05-10T21:29:23.835305Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"best_f1 = 0.0\npatience = 3\nepochs_without_improvement = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:29:23.836739Z","iopub.execute_input":"2025-05-10T21:29:23.837262Z","iopub.status.idle":"2025-05-10T21:29:23.841139Z","shell.execute_reply.started":"2025-05-10T21:29:23.837238Z","shell.execute_reply":"2025-05-10T21:29:23.840352Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"for epoch in range(10):\n    model.train()\n    total_loss = 0\n    for X, y in train_loader:\n        X, y = X.to(device), y.to(device)\n        optimizer.zero_grad()\n        preds = model(X)\n        loss = criterion(preds, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    # Evaluate\n    acc, f1 = evaluate(test_loader)\n    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Test Acc: {acc:.4f}, F1: {f1:.4f}\")\n\n    # Early stopping\n    if f1 > best_f1:\n        best_f1 = f1\n        epochs_without_improvement = 0\n    else:\n        epochs_without_improvement += 1\n        if epochs_without_improvement >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:29:23.842790Z","iopub.execute_input":"2025-05-10T21:29:23.843485Z","iopub.status.idle":"2025-05-10T21:33:32.646697Z","shell.execute_reply.started":"2025-05-10T21:29:23.843467Z","shell.execute_reply":"2025-05-10T21:33:32.646093Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 322.7507, Test Acc: 0.8517, F1: 0.8671\nEpoch 2, Loss: 182.8774, Test Acc: 0.8904, F1: 0.8848\nEpoch 3, Loss: 121.6934, Test Acc: 0.8920, F1: 0.8911\nEpoch 4, Loss: 85.8199, Test Acc: 0.8775, F1: 0.8837\nEpoch 5, Loss: 65.9822, Test Acc: 0.8515, F1: 0.8362\nEpoch 6, Loss: 55.8267, Test Acc: 0.8717, F1: 0.8641\nEarly stopping at epoch 6\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"torch.save(model.state_dict(), \"complete_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:33:32.647971Z","iopub.execute_input":"2025-05-10T21:33:32.648157Z","iopub.status.idle":"2025-05-10T21:33:32.801841Z","shell.execute_reply.started":"2025-05-10T21:33:32.648143Z","shell.execute_reply":"2025-05-10T21:33:32.801023Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model = torch.load(\"complete_model.pth\")\nmodel.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}